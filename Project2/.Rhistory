abline(h = 0, lty = 2)
plot(logit.overall$fitted.values)
plot(logit.overall$residuals)
influencePlot(logit.overall)
influence(logit.overall)
Plotinfluence(logit.overall)
Plot.influence(logit.overall)
influencePlot(add$LC)
influencePlot(logit.overall)
influencePlot(logit.overall)
#-Intercept: The log odds of a student getting admitted to a graduate school
#            when they attended a top tier undergraduate school and received a
#            0 on the GRE and a 0 as their GPA is approximately -3.990.
#-GRE: For every additional point a student scores on the GRE, their log odds
#      of being admitted to graduate school increase by approximately 0.002,
#      holding all other variables constant.
#-GPA: For every additional point a student raises their GPA, their log odds of
#      being admitted to graduate school increase by approximately 0.804, holding
#      all other variables constant.
#-Rank: The change in log odds associated with attending an undergraduate school
#       with prestige of rank 2, 3, and 4, as compared to a school with prestige
#       rank 1, is approximately -0.675, -1.340, and -1.552, respectively, holding
#       all other variables constant.
exp(logit.overall$coefficients)
exp(logit.overall$coefficients)
cbind("Log Odds" = logit.overall$coefficients,
"Odds" = exp(logit.overall$coefficients))
plot(logit.overall$fitted.values)
library(car)
influencePlot(logit.overall)
summary(logit.overall)
table(add$LC,add$BK)
exp(logit.overall$coefficients)
df = read.json('train.csv')
epsilon_ber <- 2*rbinom(100,1,p=0.5)-1     # converting the values 0, 1 to -1, 1
x_ber <- cumsum(epsilon_ber)
plot(x_ber, type='l')
# Gaussian random walk
# rbinom with size = 1 is nothing but Bernoulli distribution
epsilon_ber <- 2*rbinom(100,1,p=0.5)-1     # converting the values 0, 1 to -1, 1
x_ber <- cumsum(epsilon_ber)
plot(x_ber, type='l')
# Gaussian random walk
epsilon_norm <- rnorm(100, 0, sd=0.1)
x_norm <- cumsum(epsilon_norm)
plot(x_norm, type='l')
# 2D random walks
# Bernoulli random walk
N<-10000
epsilon1_ber <-  2 * rbinom(N,1,p=0.5) - 1
epsilon2_ber <-  2 * rbinom(N,1,p=0.5) - 1
x_ber <-  cumsum(epsilon1_ber)
y_ber <-  cumsum(epsilon2_ber)
plot(x_ber, y_ber, type='l')
# Gaussian random walk
N<-10000
epsilon1_norm <-  rnorm(N,0,0.1)
epsilon2_norm <-  rnorm(N,0,0.1)
x_norm <-  cumsum(epsilon1_norm)
y_norm <-  cumsum(epsilon2_norm)
plot(x_norm, y_norm, type='l')
# SnP500 index price series
library(quantmod)
sp500<-new.env()
getSymbols('^GSPC',env=sp500, src='yahoo', from=as.Date('1960-01-04'),
to=as.Date('2017-03-17'))
head(sp500$GSPC)
tail(sp500$GSPC)
#header: GSPC.Open GSPC.High GSPC.Low GSPC.Close GSPC.Volume GSPC.Adjusted
class(sp500$GSPC)
sp_prc<-sp500$GSPC[,6]
class(sp_prc)    # xts, zoo      'zoo' stands for Z's ordered observations
# xts can handle irregular period time series as well as regular time series
#1960-01-04         59.91
#2017-03-17       2378.25
# total return    (2372.60-59.91)/59.91 ~ 39.60
# daily return
plot(sp_prc)
ret_sp500_daily<-(sp_prc-lag(sp_prc))/lag(sp_prc)
#or
ret_sp500_daily<-diff(sp_prc)/lag(sp_prc)
plot(ret_sp500_daily)
mean(ret_sp500_daily,na.rm=T) * 252     # annualized return
# 0.0771279 ~ 7.7%
# This excludes the yearly dividends paid out to the investors
# the SP500's dividend yield is currently ~2%, the longer term average is 3-5%.
# total return is >= 10%/year
# to get the time series with dividends, use the ETF ticker = SPY
spy<-new.env()
getSymbols('SPY',env=spy, src='yahoo', from=as.Date('1993-01-29'),
to=as.Date('2017-03-17'))
head(spy$SPY)
spy_prc <- spy$SPY[,6]
ret_spy_daily <- diff(spy_prc)/lag(spy_prc)
mean(ret_spy_daily, na.rm=T) * 252   # ~ 10.6097  vs  8.68% for SPX in the same period
# rollmean
sp_avg20 = rollmean(sp_prc, 20, align='center')
plot(sp_avg20)
sp_avg100 = rollmean(sp_prc, 100, align='center')
plot(sp_avg100)
ret_sp500_daily<-ret_sp500_daily[2:length(ret_sp500_daily)]  # removing the first nan element
ret_sp500_avg20 = rollmean(ret_sp500_daily, 20, align='center')
plot(ret_sp500_avg20)
ret_sp500_avg100 = rollmean(ret_sp500_daily, 100, align='center')
plot(ret_sp500_avg100)       # The 100 trading days moving average is smoother than the 20 days version
# The 1987 Black Monday drops 20% in a day, but its effect is smoothed out after 100-day moving window
# Now the most significant drop becomes the finanical crisis during 2008-2009
# test for stationary
# adf.test
library(tseries)
adf.test(sp_prc)
#Augmented Dickey-Fuller Test
#data:  sp_prc
#Dickey-Fuller = -0.59095, Lag order = 24, p-value = 0.9777
#alternative hypothesis: stationary
# 97.7% probability it is NOT a stationary time series
# This can be seen by the naked eye
adf.test(ret_sp500_daily)
#data:  ret_sp500_daily
#Dickey-Fuller = -24.578, Lag order = 24, p-value = 0.01
#alternative hypothesis: stationary
#Warning message:
#  In adf.test(ret_sp500_daily) : p-value smaller than printed p-value
# About < 1% chance to be a non-stationary time series
sp_logPrc <- log(sp_prc)
logRet_sp500_daily <- diff(sp_logPrc)
logRet_sp500_daily <- logRet_sp500_daily[2:length(logRet_sp500_daily)]
adf.test(logRet_sp500_daily)
#Augmented Dickey-Fuller Test
#data:  logRet_sp500_daily
#Dickey-Fuller = -24.315, Lag order = 24, p-value = 0.01
#alternative hypothesis: stationary
#Warning message:
#  In adf.test(logRet_sp500_daily) : p-value smaller than printed p-value
### Some simulated time series to demonstrate the usage of augumented Fuller-Dickey test
#
N <- 100
sigma <- 0.1
epsilon = rnorm(N, 0, sigma)
X <- numeric(N)
theta <- 0.2
X[1]  <- 2.0
for (i in 2:N) {
X[i] <- theta * X[i-1] + epsilon[i]
}
adf.test(X)
set.seed(0)
N <- 100
sigma <- 0.1
epsilon = rnorm(N, 0, sigma)
X <- numeric(N)
theta <- 0.95
X[1]  <- 2.0
for (i in 2:N) {
X[i] <- theta * X[i-1] + epsilon[i]
}
adf.test(X)
# > 46% chance it is a non-stationary time series
# actually such an AR(1) time series is indeed stationary
set.seed(0)
N <- 1000
sigma <- 0.1
epsilon = rnorm(N, 0, sigma)
X <- numeric(N)
theta <- 0.95
X[1]  <- 2.0
for (i in 2:N) {
X[i] <- theta * X[i-1] + epsilon[i]
}
adf.test(X)
# Increasing N to 1000, p-value drops to <1%
# Conclusion:  The accuracy of the adf.test depends on the sample size
# Do not apply the statistical test blindly
set.seed(0)
N <- 100
sigma <- 0.01
epsilon = rnorm(N, 0, sigma)
X <- numeric(N)
theta <- 0.95
X[1]  <- 2.0
for (i in 2:N) {
X[i] <- theta * X[i-1] + epsilon[i]
}
adf.test(X)
N <- 100
sigma <- 0.1
epsilon = rnorm(N, 0, sigma)
X <- numeric(N)
theta <- 0.5
X[1]  <- 2.0
for (i in 2:N) {
X[i] <- theta * X[i-1] + epsilon[i]
}
acf(X, lag.max=10)  # lag.max = 10 to plot only the 10 terms
acf(X, lag.max=10)  # lag.max = 10 to plot only the 10 terms
N <- 1000
sigma <- 0.1
epsilon = rnorm(N, 0, sigma)
X <- numeric(N)
theta <- 0.5
X[1]  <- 2.0
for (i in 2:N) {
X[i] <- theta * X[i-1] + epsilon[i]
}
acf(X, lag.max=10)  # The noise in the auto-correlation function reduces as N goes large
acf(ret_sp500_daily, lag.max=100)   # The stock index is generally efficient, there is no long term pattern
sp500_vola_daily <-rollapply(ret_sp500_daily, width=100, FUN=sd)
plot(sp500_vola_daily)
?decribe
?describe
df<-data.frame(ad:fuck)
df<-data.frame({ad=fuck})
df<-data.frame(FOO=1:4,bar =c(T,T,F,F))
ncol(x)
ncol(df)
names(df)
row.names(df)
colnames(df)[colnames(df)=="FOO"] <- "NEW"
names(df)
?doBY
df.factor()
x<-factor(c(0,4,3,3,4))
str(x)
x1<-as.numeric(x)
str(x)
a2 = as.numeric(as.character(x))
str(a2)
x[[1]]
Lst<-list(name="Free",wife="frees",no.children=3,child.ages=c(4,7,9))
Lst[[1]]
x<-paste(c("X","Y"),1:2,sep = '')
x
x<-list("Los"=1,boston=2)
x
names(x)<-c("N","M")
x
x<-list(c(1,2,3,4))
x.as_
unlist(a)
unlist(c)
unlist(x)
x.vector()
vector(a)
a<-array(c(0:1,1:0),dim=c(2,2))
a %*% a
x=0
y=10
f=function() {}
f=function() {}
f=function() { x=1 g()}
x= c(0,1,2,3,4,5,6,7,8,9)
x[-(1:3)]
country<-c("uk","brain","rogers")
hourly <- c(10,20,30)
bwplot
x= c(1:3,NA)
Y=is.na(x)
y
Y
num=5;res=1;for (i in 1:num)  { if (i%%2==0) {res = res*1}}; res
x= array(0:7,dim=c(2,2,2))
x= array(0:7,dim=c(1:2,4:3),dimc(2,2))
i= array(0:7,dim=c(1:2,4:3),dimc(2,2))
i= array(c(1:2,4:3),dimc(2,2))
x= array(0:7,dim=c(2,2,2))
i= array(c(1:2,4:3),dim=c(2,2))
x[i]
?uniPlot
setwd("~/Upwork/Project2")
library(tree)
#Loading the ISLR library in order to use the Carseats dataset.
library(ISLR)
df = read.csv('retention.csv')
hist(df)
summary(df)
View(df)
df = read.csv('retention.csv')
#Looking at the variable of interest, Sales.
summary(df)
View(df)
High = ifelse(df$Cohort_period < 2, "No", "Yes")
df = data.frame(df, High)
tree.retention = tree(High ~ . - Cohort_period, split = "gini", data = df)
library(tree)
library(ISLR)
df = read.csv('retention.csv')
df$platform = as.factor(df$platform)
df$ip_ip = as.factor(df$ip_ip)
df$ip_country = as.factor(df$ip_country)
df$ip_region = as.factor(df$ip_region)
df$ip_city = as.factor(df$ip_city)
df$ip_timezone = as.factor(df$ip_timezone)
df$client_mobile_os = as.factor(df$client_mobile_os)
df$client_mobile_device = as.factor(df$client_mobile_device)
df$client_mobile_language = as.factor(df$client_mobile_language)
df$client_mobile_uid = as.factor(df$client_mobile_uid)
df$client_mobile_device_aid = as.factor(df$client_mobile_device_aid)
df$register_os = as.factor(df$register_os)
df$register_ip_region = as.factor(df$register_ip_region)
df$register_ip_city = as.factor(df$register_ip_city)
tree.retention = tree(High ~ . - Cohort_period, split = "gini", data = df)
View(df)
df = df[, !(colnames(df) %in% c("register_ip_city","","register_ip_region","ip_ip","client_mobile_device","client_mobile_language","client_mobile_uid","client_mobile_device_aid","ip_country","ip_region","ip_city",""))]
View(df)
tree.retention = tree(High ~ . - Cohort_period, split = "gini", data = df)
summary(tree.carseats)
summary(tree.retention)
plot(tree.retention)
tree.retention = tree(High ~ . - Cohort_period, split = "gini", data = df)
summary(tree.retention)
df = data.frame(df, High)
df$High
tree.retention = tree(High ~ . - Cohort_period, split = "gini", data = df)
summary(tree.retention)
plot(tree.retention)
text(tree.retention, pretty = 0) #Yields category names instead of dummy variables.
df = read.csv('retention.csv')
df$platform = as.factor(df$platform)
df$ip_ip = as.factor(df$ip_ip)
df$ip_country = as.factor(df$ip_country)
df$ip_region = as.factor(df$ip_region)
df$ip_city = as.factor(df$ip_city)
df$ip_timezone = as.factor(df$ip_timezone)
df$client_mobile_os = as.factor(df$client_mobile_os)
df$client_mobile_device = as.factor(df$client_mobile_device)
df$client_mobile_language = as.factor(df$client_mobile_language)
df$client_mobile_uid = as.factor(df$client_mobile_uid)
df$client_mobile_device_aid = as.factor(df$client_mobile_device_aid)
df$register_os = as.factor(df$register_os)
df$register_ip_region = as.factor(df$register_ip_region)
df$register_ip_city = as.factor(df$register_ip_city)
High = ifelse(df$Cohort_period < 2, "No", "Yes")
df = data.frame(df, High)
tree.retention = tree(High ~ . - Cohort_period, split = "gini", data = df)
df = df[, !(colnames(df) %in% c("register_ip_city","","register_ip_region","ip_ip","client_mobile_device","client_mobile_language","client_mobile_uid","client_mobile_device_aid","ip_country","ip_region","ip_city",""))]
tree.retention = tree(High ~ . - Cohort_period, split = "gini", data = df)
tree.retention = tree(High ~ . - Cohort_period, split = "gaussian", data = df)
tree.retention = tree(High ~ . - Cohort_period, split = "deviance", data = df)
summary(tree.retention)
#The output shows the variables actually used within the tree, the number of
#terminal nodes, the residual mean deviance based on the Gini index, and
#the misclassification error rate.
#Plotting the classification tree.
plot(tree.retention)
text(tree.retention, pretty = 0) #Yields category names instead of dummy variables.
set.seed(0)
train = sample(1:nrow(df), 7*nrow(df)/10) #Training indices.
df.test = df[-train, ] #Test dataset.
High.test = High[-train] #Test response.
#Ftting and visualizing a classification tree to the training data.
tree.retention = tree(High ~ . - Cohort_period, data = df, subset = train)
plot(tree.retention)
text(tree.retention, pretty = 0)
tree.pred = predict(tree.retention, df.test, type = "class")
tree.pred
#Assessing the accuracy of the overall tree by constructing a confusion matrix.
table(tree.pred, High.test)
(60 + 42)/120
High.test
tree.pred[0]
High.test[0]
High.test[1]
tree.pred[1]
tree.pred[1:10]
High.test[1:10]
tree.pred[1:100]
High.test[1:100]
set.seed(0)
cv.df = cv.tree(tree.df, FUN = prune.misclass)
cv.df = cv.tree(tree.retention, FUN = prune.misclass)
cv.retention = cv.tree(tree.retention, FUN = prune.misclass)
names(cv.retention)
cv.retention = cv.tree(tree.retention, FUN = prune.misclass)
par(mfrow = c(1, 1))
prune.retention = prune.misclass(tree.retention, best = 4)
plot(prune.retention)
text(prune.retention, pretty = 0)
tree.pred = predict(prune.retention, df.test, type = "class")
table(tree.pred, High.test)
library(MASS)
set.seed(0)
train = sample(1:nrow(df), 7*nrow(df)/10)
library(tree)
library(ISLR)
df = read.csv('retention.csv')
df$platform = as.factor(df$platform)
df$ip_ip = as.factor(df$ip_ip)
df$ip_country = as.factor(df$ip_country)
df$ip_region = as.factor(df$ip_region)
df$ip_city = as.factor(df$ip_city)
df$ip_timezone = as.factor(df$ip_timezone)
df$client_mobile_os = as.factor(df$client_mobile_os)
df$client_mobile_device = as.factor(df$client_mobile_device)
df$client_mobile_language = as.factor(df$client_mobile_language)
df$client_mobile_uid = as.factor(df$client_mobile_uid)
df$client_mobile_device_aid = as.factor(df$client_mobile_device_aid)
df$register_os = as.factor(df$register_os)
df$register_ip_region = as.factor(df$register_ip_region)
df$register_ip_city = as.factor(df$register_ip_city)
df = df[, !(colnames(df) %in% c("register_ip_city","","register_ip_region","ip_ip","client_mobile_device","client_mobile_language","client_mobile_uid","client_mobile_device_aid","ip_country","ip_region","ip_city",""))]
tree.retention1 = tree(Cohort_period ~ ., df, subset = train)
summary(tree.retention1)
summary(tree.retention1)
plot(tree.boston)
plot(tree.retention1)
text(tree.retention1, pretty = 0)
text(tree.retention1, pretty = 1)
text(tree.retention1, pretty = 2)
text(tree.retention1, pretty = 0)
plot(tree.retention1)
text(tree.retention1, pretty = 0)
High = ifelse(df$Cohort_period < 2, "No", "Yes")
df = data.frame(df, High)
tree.retention1 = tree(High ~ -Cohort_period, df, subset = train)
summary(tree.retention1)
#Visually inspecting the regression tree.
plot(tree.retention1)
text(tree.retention1, pretty = 0)
tree.retention1 = tree(High ~ -Cohort_period, df, subset = train)
summary(tree.retention1)
#Visually inspecting the regression tree.
tree.retention1 = tree(Cohort_period ~ -High, df, subset = train)
summary(tree.retention1)
#Visually inspecting the regression tree.
plot(tree.retention1)
text(tree.retention1, pretty = 0)
tree.retention1 = tree(High ~ . - Cohort_period, df, subset = train)
summary(tree.retention1)
#Visually inspecting the regression tree.
plot(tree.retention1)
text(tree.retention1, pretty = 0)
#Performing cross-validation.
set.seed(0)
cv.retention1 = cv.tree(tree.retention1)
prune.retention1 = prune.tree(tree.retention1, best = 4)
par(mfrow = c(1, 1))
plot(prune.boston)
text(prune.boston, pretty = 0)
plot(prune.retention1)
text(prune.retention1, pretty = 0)
#Calculating and assessing the MSE of the test data on the overall tree.
yhat = predict(tree.retention1, newdata = df[-train, ])
yhat
df.test = df[-train, "High"]
df.test
plot(yhat, df.test)
abline(0, 1)
mean((yhat - df)^2)
mean((yhat - df.test)^2)
#Calculating and assessing the MSE of the test data on the pruned tree.
tree.retention1 = tree(Cohort_period ~ . - High, df, subset = train)
summary(tree.retention1)
#Visually inspecting the regression tree.
plot(tree.retention1)
text(tree.retention1, pretty = 0)
prune.retention1 = prune.tree(tree.retention1, best = 5)
par(mfrow = c(1, 1))
plot(prune.retention1)
text(prune.retention1, pretty = 0)
prune.retention1 = prune.tree(tree.retention1, best = 6)
par(mfrow = c(1, 1))
plot(prune.retention1)
text(prune.retention1, pretty = 0)
prune.retention1 = prune.tree(tree.retention1, best = 7)
par(mfrow = c(1, 1))
plot(prune.retention1)
text(prune.retention1, pretty = 0)
prune.retention1 = prune.tree(tree.retention1, best = 8)
par(mfrow = c(1, 1))
plot(prune.retention1)
text(prune.retention1, pretty = 0)
prune.retention1 = prune.tree(tree.retention1, best = 9)
par(mfrow = c(1, 1))
plot(prune.retention1)
text(prune.retention1, pretty = 0)
prune.retention1 = prune.tree(tree.retention1, best = 10)
par(mfrow = c(1, 1))
plot(prune.retention1)
text(prune.retention1, pretty = 0)
library(randomForest)
#Fitting an initial random forest to the training subset.
set.seed(0)
rf.retention = randomForest(High ~ . - Cohort_period, data = df, subset = train, importance = TRUE)
rf.retention
#The MSE and percent variance explained are based on out-of-bag estimates,
#yielding unbiased error estimates. The model reports that mtry = 4, which is
#the number of variables randomly chosen at each split. Since we have 13 overall
#variables, we could try all 13 possible values of mtry. We will do so, record
#the results, and make a plot.
#Varying the number of variables used at each step of the random forest procedure.
set.seed(0)
oob.err = numeric(13)
for (mtry in 1:13) {
fit = randomForest(High ~ . - Cohort_period, data = df[train, ], mtry = mtry)
oob.err[mtry] = fit$mse[500]
cat("We're performing iteration", mtry, "\n")
}
plot(1:13, oob.err, pch = 16, type = "b",
xlab = "Variables Considered at Each Split",
ylab = "OOB Mean Squared Error",
main = "Random Forest OOB Error Rates\nby # of Variables")
#Can visualize a variable importance plot.
importance(rf.boston)
varImpPlot(rf.boston)
library(gbm)
#Fitting 10,000 trees with a depth of 4.
set.seed(0)
boost.retention = gbm(High ~ . - Cohort_period, data = df,
distribution = "gaussian",
n.trees = 7000,
interaction.depth = 4)
summary(boost.retention)
